{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75359cd7-9574-4eeb-a153-ccb6c8c584c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'D:\\Work\\VGG19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23245227-40d4-40fe-8e33-e862c23f26dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bfda2-383f-4157-bbb1-cf542fede970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e961a-1770-4eda-9f52-e8ad5989ae61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "# 批次处理大小\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b7301a-3191-4fcc-b869-53a4f0883677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 图像像元值归一化处理器 0-255 ~ 0-1\n",
    "train_datagen = image.ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = image.ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc040d-c413-445f-98ca-50f22919240a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 影像处理，分类器\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),      # resize大小\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')         \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02582490-786c-4b93-9a83-99c68c06a867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet', \n",
    "                   include_top=False,\n",
    "                   input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e02c3-622c-442b-a37f-3aab4916be66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66dd9f3-68dc-4e18-8ec8-791c9e4105f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, GlobalMaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187ebd0-5f38-484f-b596-2d462e94bed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用VGG 19提取图片特征\n",
    "def extractFeatures(data_generator):\n",
    "    i = 0\n",
    "    sample_count = len(data_generator.filenames)\n",
    "    features = []\n",
    "    labels = []\n",
    "    for inputs_batch, labels_batch in data_generator:\n",
    "        features_batch = base_model.predict(inputs_batch)\n",
    "        features.append(features_batch)\n",
    "        labels.append(labels_batch)\n",
    "        i += 1\n",
    "        if i*batch_size >= sample_count:\n",
    "            break\n",
    "    features = np.concatenate(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    return features, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f223a47-e659-4c7d-b74a-176b0e070c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features, train_lables = extractFeatures(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607d2dc-6f90-40d3-88f8-0144ad30b4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features, test_lables = extractFeatures(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287af82-a770-4466-a291-1b332b08fe82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# 池化输入层，压缩数据\n",
    "model.add(GlobalMaxPooling2D(input_shape=(7,7,512)))\n",
    "# 全连接层，特征提取器\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Dropout 防止过拟合 \n",
    "model.add(Dropout(0.5))\n",
    "# 输出层 sigmoid激活函数用于二分类输出 softmax用于多分类输出\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c1b96-9e2c-4b7d-96b2-aca4bcbd3867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型编译\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865aaab9-0c46-400b-82b8-e05ed70ef64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_lables,\n",
    "    epochs=20,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(test_features, test_lables)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35bf55-0c50-4460-beb7-9e085475d1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_features, test_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9e10c-4dcc-45d7-a412-9364ad974062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8e325-abf8-43e5-9bb4-18a35f97569f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob(\"predict/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6cedc-bda5-4a2f-9f4d-f75e3fe37fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a3ec51-2a51-482f-8ba2-f035d953fbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_data = []\n",
    "for file in files:\n",
    "    img = image.image_utils.load_img(file, target_size=(224, 224))\n",
    "    data = image.image_utils.img_to_array(img) / 255\n",
    "    predict_data.append(data)\n",
    "predict_data = np.array(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be3e5b-f5ed-4bdf-acf8-7d11cb83ff02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546fd03-22d8-4404-89f5-cbc02f790bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_features = base_model.predict(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3bad3-ed5d-49ce-8716-468487a88319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ed317-8d0e-44c7-aa41-bd62a85ec114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_result = model.predict(predict_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f742a-a9d7-460b-bfc7-f32c529f5f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.around(predict_result, decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67bde1-5b64-45fc-8994-09762f6ed366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad840d0-75ae-43d6-b4a2-9f885748a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c565cee-25d9-4a6f-bb7c-7010a9ec3c06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b804d-ac97-4dcf-83fc-8251d43e9b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
